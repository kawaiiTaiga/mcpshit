import openwakeword
from openwakeword.model import Model
import pyaudio
import numpy as np
from datetime import datetime
import time
import requests
import io
import threading
import os
import pygame
import pyautogui
import pyperclip
import wave

# Status Constants
STATUS_IDLE = "idle"           # Sleeping
STATUS_LISTENING = "listening" # Waiting for wakeword
STATUS_WAKED = "waked"         # Wakeword detected
STATUS_RECORDING = "recording" # Recording voice
STATUS_PROCESSING = "processing" # Sending to Whisper
STATUS_TYPED = "typed"         # Text typed

class WakeWordClient:
    def __init__(self, 
                 wakeword_models=["ruby_chan.onnx"],
                 whisper_server_url="http://localhost:8000",
                 wakeword_threshold=0.5,
                 max_recording_duration=10.0,
                 silence_duration=1.5,
                 silence_threshold=500,
                 cooldown_time=3.0,
                 overlay_image_path="overlay.png",
                 overlay_duration_ms=1500,
                 overlay_sound_file=None,
                 log_callback=None,
                 on_wakeword=None,
                 status_callback=None
                 ):
        """
        Wake Word ê°ì§€ + ë…¹ìŒ í´ë¼ì´ì–¸íŠ¸
        """
        self.log_callback = log_callback
        self.on_wakeword = on_wakeword
        self.status_callback = status_callback
        self.log("Wake Word ëª¨ë¸ ë¡œë”© ì¤‘... (CPU)")
        
        # ëª¨ë¸ ê²½ë¡œ í™•ì¸ ë° ë¡œë“œ
        valid_models = []
        for model in wakeword_models:
            if os.path.exists(model):
                valid_models.append(model)
            else:
                self.log(f"âš ï¸ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model}")
        
        if not valid_models:
            self.log("âŒ ìœ íš¨í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        self.wakeword_model = Model(wakeword_models=valid_models)
        
        self.whisper_server_url = whisper_server_url
        self.wakeword_threshold = wakeword_threshold
        self.max_recording_duration = max_recording_duration
        self.silence_duration = silence_duration
        self.silence_threshold = silence_threshold
        self.cooldown_time = cooldown_time
        
        self.overlay_image_path = overlay_image_path
        self.overlay_duration_ms = overlay_duration_ms
        self.overlay_sound_file = overlay_sound_file
        
        self.last_wakeword_time = 0
        self.running = False
        
        # PyAudio ì„¤ì •
        self.FORMAT = pyaudio.paInt16
        self.CHANNELS = 1
        self.RATE = 16000
        self.CHUNK = 1280
        
        self.audio = None # ì´ˆê¸°í™” ì§€ì—°
        
        self._test_server_connection()
        self.log("ì´ˆê¸°í™” ì™„ë£Œ!")

    def log(self, message):
        print(message)
        if self.log_callback:
            self.log_callback(message)

    def update_status(self, status):
        if self.status_callback:
            self.status_callback(status)

    def stop(self):
        self.running = False
        self.update_status(STATUS_IDLE)

    def _test_server_connection(self):
        try:
            response = requests.get(f"{self.whisper_server_url}/health", timeout=5)
            if response.status_code == 200:
                self.log(f"âœ… Whisper ì„œë²„ ì—°ê²° ì„±ê³µ: {self.whisper_server_url}")
            else:
                self.log(f"âš ï¸  Whisper ì„œë²„ ì‘ë‹µ ì´ìƒ: {response.status_code}")
        except Exception as e:
            self.log(f"âŒ Whisper ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {e}")

    def type_text_and_enter(self, text):
        """í…ìŠ¤íŠ¸ ì…ë ¥ ë° ì—”í„°"""
        try:
            pyperclip.copy(text)
            pyautogui.hotkey('ctrl', 'v')
            time.sleep(0.1)
            pyautogui.press('enter')
            self.log(f"âœ… í…ìŠ¤íŠ¸ ì…ë ¥ ì™„ë£Œ: '{text}'")
            self.update_status(STATUS_TYPED)
        except Exception as e:
            self.log(f"âŒ í…ìŠ¤íŠ¸ ì…ë ¥ ì—ëŸ¬: {e}")
    
    def play_sound(self):
        if self.overlay_sound_file and os.path.exists(self.overlay_sound_file):
            try:
                pygame.mixer.init()
                pygame.mixer.music.load(self.overlay_sound_file)
                pygame.mixer.music.play()
            except Exception as e:
                self.log(f"âŒ ì‚¬ìš´ë“œ ì—ëŸ¬: {e}")

    def calculate_rms(self, audio_chunk):
        audio_array = np.frombuffer(audio_chunk, dtype=np.int16).astype(np.float32)
        rms = np.sqrt(np.mean(audio_array**2))
        return rms
    
    def record_audio_with_vad(self):
        self.update_status(STATUS_RECORDING)
        self.log(f"ğŸ¤ ë…¹ìŒ ì‹œì‘... (ìµœëŒ€ {self.max_recording_duration}ì´ˆ)")
        
        stream = self.audio.open(
            format=self.FORMAT,
            channels=self.CHANNELS,
            rate=self.RATE,
            input=True,
            frames_per_buffer=self.CHUNK
        )
        
        frames = []
        silent_chunks = 0
        max_silent_chunks = int(self.silence_duration / (self.CHUNK / self.RATE))
        max_chunks = int(self.max_recording_duration / (self.CHUNK / self.RATE))
        
        recording_started = False
        
        for i in range(max_chunks):
            if not self.running: break
            data = stream.read(self.CHUNK)
            frames.append(data)
            
            rms = self.calculate_rms(data)
            
            if rms > self.silence_threshold:
                silent_chunks = 0
                recording_started = True
            else:
                if recording_started:
                    silent_chunks += 1
            
            if recording_started and silent_chunks >= max_silent_chunks:
                break
        
        stream.stop_stream()
        stream.close()
        
        return b''.join(frames)
    
    def transcribe_via_server(self, audio_data):
        self.update_status(STATUS_PROCESSING)
        self.log("ğŸ”„ Whisper ì„œë²„ë¡œ ì „ì†¡ ì¤‘...")
        try:
            files = {'audio': ('audio.raw', io.BytesIO(audio_data), 'application/octet-stream')}
            response = requests.post(
                f"{self.whisper_server_url}/transcribe",
                files=files,
                timeout=30
            )
            if response.status_code == 200:
                result = response.json()
                return result.get('text', '')
            else:
                self.log(f"âŒ ì„œë²„ ì—ëŸ¬: {response.status_code}")
                return ""
        except Exception as e:
            self.log(f"âŒ ì „ì†¡ ì‹¤íŒ¨: {e}")
            return ""
    
    def run(self):
        self.running = True
        self.update_status(STATUS_LISTENING)
        self.log("\n" + "="*60)
        self.log("ğŸ§ ë§ˆì´í¬ ë¦¬ìŠ¤ë‹ ì¤‘...")
        self.log("="*60 + "\n")
        
        try:
            self.audio = pyaudio.PyAudio()
            
            while self.running:
                stream = self.audio.open(
                    format=self.FORMAT,
                    channels=self.CHANNELS,
                    rate=self.RATE,
                    input=True,
                    frames_per_buffer=self.CHUNK
                )
                
                wakeword_detected = False
                
                while not wakeword_detected and self.running:
                    data = stream.read(self.CHUNK, exception_on_overflow=False)
                    audio_data = np.frombuffer(data, dtype=np.int16)
                    
                    # ì¿¨ë‹¤ìš´ ì²´í¬ (ë£¨í”„ ì‹œì‘ ì‹œ)
                    if time.time() - self.last_wakeword_time < self.cooldown_time:
                        continue

                    prediction = self.wakeword_model.predict(audio_data)
                    
                    for model_name, score in prediction.items():
                        if score > self.wakeword_threshold:
                            self.log(f"âœ¨ Wake Word '{model_name}' ê°ì§€! ({score:.3f})")
                            self.update_status(STATUS_WAKED)
                            
                            # 1. ì½œë°± í˜¸ì¶œ (GUI ì˜¤ë²„ë ˆì´ìš©)
                            if self.on_wakeword:
                                self.on_wakeword()
                            
                            # 2. ì‚¬ìš´ë“œ ì¬ìƒ
                            threading.Thread(target=self.play_sound, daemon=True).start()
                            
                            wakeword_detected = True
                            break
                
                stream.stop_stream()
                stream.close()
                
                if not self.running: break

                if wakeword_detected:
                    # ëª¨ë¸ ìƒíƒœ ë¦¬ì…‹ (ì¤‘ë³µ ê°ì§€ ë°©ì§€)
                    self.wakeword_model.reset()
                    
                    audio_data = self.record_audio_with_vad()
                    text = self.transcribe_via_server(audio_data)
                    
                    if text:
                        self.log(f"ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸: '{text}'")
                        threading.Thread(target=self.type_text_and_enter, args=(text,), daemon=True).start()
                    else:
                        self.log("âš ï¸  ìŒì„±ì´ ì¸ì‹ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                    
                    # ì¿¨ë‹¤ìš´ ì‹œì‘ (ëª¨ë“  ì‘ì—… ì™„ë£Œ í›„)
                    self.last_wakeword_time = time.time()
                    self.log(f"ì¿¨ë‹¤ìš´ ì‹œì‘: {self.cooldown_time}ì´ˆ")
                    time.sleep(self.cooldown_time)
                    self.update_status(STATUS_LISTENING)
                    self.log("ğŸ§ ë‹¤ì‹œ ëŒ€ê¸° ì¤‘...")
                        
        except Exception as e:
            self.log(f"Error in run loop: {e}")
        finally:
            if self.audio:
                self.audio.terminate()
                self.audio = None
            try:
                pygame.mixer.quit()
            except:
                pass

if __name__ == "__main__":
    client = WakeWordClient()
    client.run()